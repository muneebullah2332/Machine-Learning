{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11f6c987",
   "metadata": {},
   "source": [
    "# ğŸ¬ğŸ’¸ **Bollywood Budget Predictor: Unveiling the Cost Behind the Camera with Deep Learning** ğŸ¤–âœ¨\n",
    "\n",
    "\n",
    "## **About Authur:**\n",
    "\n",
    "- Name: Muhammad Muneebullah\n",
    "\n",
    "### ğŸŒãƒ»ğ‚ğ¨ğ§ğ­ğšğœğ­ ğŒğ\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "#### ğŸ“§ ãƒ»ğ„ğ¦ğšğ¢ğ¥  \n",
    "`âœ‰ï¸` [**muneebullahmuneeb63@gmail.com**](muneebullahmuneeb63@gmail.com)\\\n",
    "*For business inquiries and collaborations*\n",
    "#### ğŸ”— ãƒ»ğ‹ğ¢ğ§ğ¤ğğğˆğ§  \n",
    "`ğŸ¢` [**Muhammad Muneeullah**](https://www.linkedin.com/in/muneebullah-muneeb-241393337/)\\\n",
    "*Let's connect professionally*\n",
    "#### ğŸ† ãƒ»ğŠğšğ ğ ğ¥ğ  \n",
    "`ğŸ“Š` [**kaggle.com/muneebullah muneeb**](https://www.kaggle.com//muneebullahmuneeb)  \n",
    "*Check out my data projects*\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "## **About Dataset(Metadata):**\n",
    "### ğŸ¬ **Movie Analytics Dataset Overview**\n",
    "\n",
    "| Column | Type | Description | Example |\n",
    "|--------|------|-------------|---------|\n",
    "| <span style=\"color:#FF6B6B\">**Movie Name**</span> | `object` | <span style=\"color:#4ECDC4\">*Title of the film*</span> | <span style=\"color:#ADD8E6\">Golden Boys</span> |\n",
    "| <span style=\"color:#FF6B6B\">**Release Period**</span> | `object` | <span style=\"color:#4ECDC4\">*Year/Season of release*</span> | <span style=\"color:#ADD8E6\">Holiday</span> |\n",
    "| <span style=\"color:#FF6B6B\">**Whether Remake**</span> | `object` | <span style=\"color:#4ECDC4\">*Is the film a remake?*</span> | <span style=\"color:#ADD8E6\">Yes/No</span> |\n",
    "| <span style=\"color:#FF6B6B\">**Whether Franchise**</span> | `object` | <span style=\"color:#4ECDC4\">*Part of a film series?*</span> | <span style=\"color:#ADD8E6\">Yes/No</span> |\n",
    "| <span style=\"color:#FF6B6B\">**Genre**</span> | `object` | <span style=\"color:#4ECDC4\">*Primary genre classification*</span> | <span style=\"color:#ADD8E6\">drama</span> |\n",
    "| <span style=\"color:#FF6B6B\">**New Actor**</span> | `object` | <span style=\"color:#4ECDC4\">*Introduces debut lead actor?*</span> | <span style=\"color:#ADD8E6\">Yes/No</span> |\n",
    "| <span style=\"color:#FF6B6B\">**New Director**</span> | <span style=\"color:#D2B48C\">`object`</span> | <span style=\"color:#4ECDC4\">*Director's first feature film?*</span> | <span style=\"color:#ADD8E6\">Yes/No</span> |\n",
    "| <span style=\"color:#FF6B6B\">**New Music Director**</span> | `object` | <span style=\"color:#4ECDC4\">*Composer's debut project?*</span> | <span style=\"color:#ADD8E6\">Yes/No</span> |\n",
    "| <span style=\"color:#FF6B6B\">**Lead Star**</span> | `object` | <span style=\"color:#4ECDC4\">*Primary actor/actress*</span> | <span style=\"color:#ADD8E6\">Aadar Jain</span> |\n",
    "| <span style=\"color:#FF6B6B\">**Director**</span> | `object` | <span style=\"color:#4ECDC4\">*Film's director*</span> | <span style=\"color:#ADD8E6\">Ravi Varma</span> |\n",
    "| <span style=\"color:#FF6B6B\">**Music Director**</span> | `object` | <span style=\"color:#4ECDC4\">*Composer/soundtrack creator*</span> | <span style=\"color:#ADD8E6\">Baba Jagirdar</span> |\n",
    "| <span style=\"color:#FF6B6B\">**Number of Screens**</span> | `integer` | <span style=\"color:#4ECDC4\">*Theatrical screens count*</span> | <span style=\"color:#ADD8E6\">5000, 8000</span> |\n",
    "| <span style=\"color:#FF6B6B\">**Revenue(INR)**</span> | `integer` | <span style=\"color:#4ECDC4\">*Box office earnings (â‚¹)*</span> | <span style=\"color:#ADD8E6\">â‚¹1200 cr, â‚¹500 cr</span> |\n",
    "| <span style=\"color:#FF6B6B\">**Budget(INR)**</span> | `integer` | <span style=\"color:#4ECDC4\">*Production cost (â‚¹)*</span> | <span style=\"color:#ADD8E6\">â‚¹300 cr, â‚¹150 cr</span> |\n",
    "\n",
    "\n",
    "## Table of Contents ğŸ“šâœ¨\n",
    "\n",
    "1. [Step 1: Import Necessary Libraries](Let's-Import-the-Libraries)\n",
    "2. [Step 2: Load the data](Load-The-Data)\n",
    "3. [Step 3: Understand the data](Let's-Understand-our-data)\n",
    "4. [Step 4: Analyze The Data](Unbolbolivariate-Analysis)\n",
    "5. [Step 5: Normalize The Data](Let's-Normalize-the-Data)\n",
    "6. [Step 6: Check the Missing Values](Let's-check-the-missing-values-in-the-data)\n",
    "7. [Step 7: Outleris Detection](Outliers)\n",
    "8. [Step 8: Deep Learning](Let's-start-the-Deep_learning)\n",
    "9. [Step 9: Saving the Model](Save-Model)\n",
    "10. [Step 10: Load the Model ](Load-the-Model)\n",
    "\n",
    "## ğŸ¯ Aims: ğŸ¥ğŸ“Š\n",
    "1. **Data Analysis**: Analyze the movie analytics dataset to understand the relationships between various features.\n",
    "2. **Data Visualization**: Visualize the data to identify trends and patterns.\n",
    "3. **Data Preprocessing**: Preprocess the data by handling missing values, outliers, and normalization.\n",
    "4. **Deep Learning**: Implement a deep learning model to predict the budget of a movie based on its features\n",
    "5. **Model Evaluation**: Evaluate the performance of the deep learning model using metrics such as mean squared error, mean absolute error, and R-squared.\n",
    "   \n",
    "## ğŸ¨âœ¨ Using Libraries For this Project ğŸ“šğŸ”§\n",
    "1. **Pandas**: For data manipulation and analysis\n",
    "2. **NumPy**: For numerical computations\n",
    "3. **Matplotlib**: For data visualization\n",
    "4. **Scikit-learn**: For data preprocessing and deep learning\n",
    "5. **TensorFlow**: For deep learning\n",
    "6. **Seaborn**: For data visualization\n",
    "7. **Plotly**: For interactive data visualization\n",
    "8. **Keras_tuner**: For hyperparameter tuning\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3a75f9",
   "metadata": {},
   "source": [
    "</div> \n",
    "<div style=\"font-size: 24px; font-weight: 600; color: #ff4d4d; background: linear-gradient(90deg, #3c1b4d, #6b2d8a); padding: 18px; border-radius: 40px; text-align: center; width: 420px; height: 60px; line-height: 60px; margin: 10px auto; box-shadow: 0 4px 12px rgba(0,0,0,0.2); font-family: 'Helvetica Neue', Arial, sans-serif; letter-spacing: 0.5px; position: relative; overflow: hidden;\">\n",
    "    <span style=\"position: relative; z-index: 1;\">âœ¨ğŸ“š Step 1: Import Libraries ğŸ“–</span>\n",
    "    <div style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; background: radial-gradient(circle, rgba(255,255,255,0.1), transparent); opacity: 0.5; z-index: 0;\"></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c05413b",
   "metadata": {},
   "source": [
    "## ğŸ”§Let's Import the Libraries ğŸ“–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225289c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import os\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import keras_tuner as kt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49854fba",
   "metadata": {},
   "source": [
    "</div> \n",
    "<div style=\"font-size: 24px; font-weight: 600; color: #ff4d4d; background: linear-gradient(90deg, #3c1b4d, #6b2d8a); padding: 18px; border-radius: 40px; text-align: center; width: 420px; height: 60px; line-height: 60px; margin: 10px auto; box-shadow: 0 4px 12px rgba(0,0,0,0.2); font-family: 'Helvetica Neue', Arial, sans-serif; letter-spacing: 0.5px; position: relative; overflow: hidden;\">\n",
    "    <span style=\"position: relative; z-index: 1;\">ğŸŒ Step 2: Load The Data ğŸ“–</span>\n",
    "    <div style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; background: radial-gradient(circle, rgba(255,255,255,0.1), transparent); opacity: 0.5; z-index: 0;\"></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960dafd2",
   "metadata": {},
   "source": [
    "## ğŸ“‚Load the data ğŸ“Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af12685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data for repository.csv') # we load the data using the csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366bc452",
   "metadata": {},
   "source": [
    "</div> \n",
    "<div style=\"font-size: 24px; font-weight: 600; color: #ff4d4d; background: linear-gradient(90deg, #3c1b4d, #6b2d8a); padding: 18px; border-radius: 40px; text-align: center; width: 420px; height: 60px; line-height: 60px; margin: 10px auto; box-shadow: 0 4px 12px rgba(0,0,0,0.2); font-family: 'Helvetica Neue', Arial, sans-serif; letter-spacing: 0.5px; position: relative; overflow: hidden;\">\n",
    "    <span style=\"position: relative; z-index: 1;\">ğŸ§  Step 3: Understand The Data ğŸ“–</span>\n",
    "    <div style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; background: radial-gradient(circle, rgba(255,255,255,0.1), transparent); opacity: 0.5; z-index: 0;\"></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf708748",
   "metadata": {},
   "source": [
    "## ğŸ“ŠLet's Understand our data ğŸ”âœ¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6266d318",
   "metadata": {},
   "source": [
    "- âœ¨First We view the data using `df.head()` command ğŸ§ğŸ“Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d245148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # for see the First five rows of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e09d74",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ“Š Let's see the Shape of the dataset ğŸ“ğŸ”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ba921",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Number of Rows in this dataset is: ', df.shape[0], 'And the Number of Columns is: ', df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab2dd28",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ“Š Let's view the information of the dataset ğŸ§ğŸ“‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e3966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # let's see the information of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66ab88e",
   "metadata": {},
   "source": [
    "- ğŸ“š Here we see there are 11 columns for object and 3 columns for integer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b799e52",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ“Š Let's see the statistical summary of the data ğŸ“ˆğŸ“‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f34c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T # we Use the T for transfrom the data it means we convert the rows into columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a310a21",
   "metadata": {},
   "source": [
    "- âœ¨ Let's only check the columns of the data ğŸ“Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4805f38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0254a49d",
   "metadata": {},
   "source": [
    "</div> \n",
    "<div style=\"font-size: 24px; font-weight: 600; color: #ff4d4d; background: linear-gradient(90deg, #3c1b4d, #6b2d8a); padding: 18px; border-radius: 40px; text-align: center; width: 420px; height: 60px; line-height: 60px; margin: 10px auto; box-shadow: 0 4px 12px rgba(0,0,0,0.2); font-family: 'Helvetica Neue', Arial, sans-serif; letter-spacing: 0.5px; position: relative; overflow: hidden;\">\n",
    "    <span style=\"position: relative; z-index: 1;\">ğŸ” Step 4: Analyze The Data ğŸ“–</span>\n",
    "    <div style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; background: radial-gradient(circle, rgba(255,255,255,0.1), transparent); opacity: 0.5; z-index: 0;\"></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319de204",
   "metadata": {},
   "source": [
    "## ğŸ¯ Univariate Analysis ğŸ“Š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926e0702",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ¥ Let's analyze the `Movie Name` Column ğŸ“ŠğŸ”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac59889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets analysis the data\n",
    "df['Movie Name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9384ffa3",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ¥ Let's see the number of unique values of the `Movie Name` column ğŸ“ŠğŸ”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e3c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Movie Name'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0027dae",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ¥ Here we see the number of unique values is **1695** in the `Movie Name` column ğŸ“ŠğŸ”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aab5a6",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ¥ Let's see the value counts of the `Movie Name` column ğŸ“ŠğŸ”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bfa592",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Movie Name'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5712025",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ” Here we see the duplicates in the `Movie Name` column, let's see with proof ğŸ“ŠğŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cce897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Movie Name'] == 'Aatma']\n",
    "df[df['Movie Name'] == 'Game']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3a21c7",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ—‘ï¸ Let's remove the duplicates in all the `dataset` ğŸ“Š\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f57d749",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates() # here we remove the duplicates in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1014bc8",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ“Š Here we see the duplicates removed ğŸ—‘ï¸âœ…\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace490ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Movie Name'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a6f7cc",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ¥ Let's see the `Genre` column ğŸ“ŠğŸ”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd103bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Genre'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4710f7a5",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ”¢ Let's see the number of unique values in this column. ğŸ“ŠğŸ”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd46838",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Genre'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb0ca48",
   "metadata": {},
   "source": [
    "- âœ¨ Here we observe the number of unique value is **14** in the `Genre` column ğŸ“ŠğŸ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c174afc",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ¥ Let's see the value counts of the `Genre` column ğŸ“ŠğŸ”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a51f78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Genre'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8eab89",
   "metadata": {},
   "source": [
    "- ğŸµ Let's we check the number of unique values in the `Music Director` column ğŸ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d104cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Music Director'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c18a1",
   "metadata": {},
   "source": [
    "- âœ¨ğŸµ Here we see the number of unique values in the `Music Director` column is **630** ğŸ“ŠğŸ”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33776b3b",
   "metadata": {},
   "source": [
    "## ğŸ“Š Bivariate Analysis ğŸ”âœ¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85541316",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ“Š Let's see the scatter plot between two columns ğŸ”ğŸ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b9d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data_frame=df, x = 'Revenue(INR)', y = 'Budget(INR)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c8f112",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ“Š Let's see the correlation plot of the numerical columns ğŸ”ğŸ“ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c678ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the correlation plot\n",
    "corr_matrix = df[['Number of Screens', 'Revenue(INR)', 'Budget(INR)']].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d78a9e",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ“Š Let's make the bar plot with plotly library between two columns ğŸ“ˆğŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f453a4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(data_frame=df, x = 'Release Period', y = 'Budget(INR)', title = 'Lead Star vs Budget')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed26ee7",
   "metadata": {},
   "source": [
    "- âœ¨ Let's see the pairplot using seaborn library ğŸ“Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7fb84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea74068",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ¥ Here the interactive visualization of the Bivariate Analysis. ğŸ“ŠğŸ”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94800ec9",
   "metadata": {},
   "source": [
    "## ğŸ“Š Multivariate Analysis ğŸ”âœ¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a91770",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ¥ Let's see the `Genre` based on the `Lead Star` ğŸ“ŠğŸ”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ab75a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Lead Star')['Genre'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6817a98e",
   "metadata": {},
   "source": [
    "- âœ¨ğŸµ Let's see the `Music Director` based on the `Lead Star` ğŸ¥ğŸ”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01574e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Lead Star')['Music Director'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac16292b",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ“Š Let's make the 3D plot between three variables ğŸ”ğŸ“ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55df8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(data_frame=df, x = 'Lead Star', y = 'Director', z = 'Budget(INR)', color = 'Revenue(INR)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9782bd8b",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ“Š Let's make the sunburst plot ğŸŒğŸ“ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0999621",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.sunburst(\n",
    "    df,\n",
    "    path=['Release Period', 'New Director', 'New Actor'],  # Hierarchical levels\n",
    "    values='Budget(INR)',  # Size of the segments\n",
    "    title='Sunburst Plot of Movie Data',  # Color segments by School Type\n",
    "    color_discrete_sequence=px.colors.qualitative.Set3  # Set color palette\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76626922",
   "metadata": {},
   "source": [
    "</div> \n",
    "<div style=\"font-size: 24px; font-weight: 600; color: #ff4d4d; background: linear-gradient(90deg, #3c1b4d, #6b2d8a); padding: 18px; border-radius: 40px; text-align: center; width: 420px; height: 60px; line-height: 60px; margin: 10px auto; box-shadow: 0 4px 12px rgba(0,0,0,0.2); font-family: 'Helvetica Neue', Arial, sans-serif; letter-spacing: 0.5px; position: relative; overflow: hidden;\">\n",
    "    <span style=\"position: relative; z-index: 1;\">ğŸ“ˆ Step 5: Normalize The Data ğŸ“–</span>\n",
    "    <div style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; background: radial-gradient(circle, rgba(255,255,255,0.1), transparent); opacity: 0.5; z-index: 0;\"></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b966355",
   "metadata": {},
   "source": [
    "## Let's Normalize the Data âœ¨ğŸ“Š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcda406",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ“Š Let's see the columns and ensure we need to normalize the data or not ğŸ”ğŸ“ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaca3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Number of Screens', 'Revenue(INR)', 'Budget(INR)']:\n",
    "    plt.figure(figsize=(6, 4))  # Optional: Adjust figure size for better visualization\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f499de0",
   "metadata": {},
   "source": [
    "- âœ¨ Here we see we need to normalize the data because our three numerical columns are very skewed ğŸ“ŠğŸ“ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d04130",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ“Š Let's Normalize the data using `log1p()` ğŸ”ğŸ“ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cec3eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Budget(INR)'] = np.log1p(df['Budget(INR)'])\n",
    "df['Revenue(INR)'] = np.log1p(df['Revenue(INR)'])\n",
    "df['Number of Screens'] = np.log1p(df['Number of Screens'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e05708",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ“Š Here our data normalized and we check it with proof âœ…ğŸ“ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b706f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Number of Screens', 'Revenue(INR)', 'Budget(INR)']:\n",
    "    plt.figure(figsize=(6, 4))  # Optional: Adjust figure size for better visualization\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f0894",
   "metadata": {},
   "source": [
    "</div> \n",
    "<div style=\"font-size: 24px; font-weight: 600; color: #ff4d4d; background: linear-gradient(90deg, #3c1b4d, #6b2d8a); padding: 18px; border-radius: 40px; text-align: center; width: 420px; height: 60px; line-height: 60px; margin: 10px auto; box-shadow: 0 4px 12px rgba(0,0,0,0.2); font-family: 'Helvetica Neue', Arial, sans-serif; letter-spacing: 0.5px; position: relative; overflow: hidden;\">\n",
    "    <span style=\"position: relative; z-index: 1;\">ğŸ” Step 6: Check Missing Values in the data ğŸ“–</span>\n",
    "    <div style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; background: radial-gradient(circle, rgba(255,255,255,0.1), transparent); opacity: 0.5; z-index: 0;\"></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609a6158",
   "metadata": {},
   "source": [
    "## ğŸ”âœ¨ Let's check the missing values in the data ğŸ“ŠğŸ“ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce4bece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a568bfb4",
   "metadata": {},
   "source": [
    "- âœ¨ Here we see there is no missing value in our data, which is great for us! âœ…ğŸ“Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dd6b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df.isnull().sum() / len(df) * 100, 2).sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53591c10",
   "metadata": {},
   "source": [
    "- ğŸ¨ğŸ“Š Let's Check with Visualization! ğŸŒŸâœ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4138dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull(), annot=True, cmap='coolwarm', cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c057123",
   "metadata": {},
   "source": [
    "</div> \n",
    "<div style=\"font-size: 24px; font-weight: 600; color: #ff4d4d; background: linear-gradient(90deg, #3c1b4d, #6b2d8a); padding: 18px; border-radius: 40px; text-align: center; width: 420px; height: 60px; line-height: 60px; margin: 10px auto; box-shadow: 0 4px 12px rgba(0,0,0,0.2); font-family: 'Helvetica Neue', Arial, sans-serif; letter-spacing: 0.5px; position: relative; overflow: hidden;\">\n",
    "    <span style=\"position: relative; z-index: 1;\">ğŸ”§ Step 7: Outliers Detection ğŸ“–</span>\n",
    "    <div style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; background: radial-gradient(circle, rgba(255,255,255,0.1), transparent); opacity: 0.5; z-index: 0;\"></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71b6fdb",
   "metadata": {},
   "source": [
    "## Outliers ğŸ”ğŸ“Š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b9a16b",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ“Š Let's see the outliers in the data with visualization. ğŸ”ğŸ“ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e280f019",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Plot all numeric columns in one big square plot with different colors for each box plot\n",
    "numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "colors = sns.color_palette(\"husl\", len(numeric_columns))  # Generate a color palette\n",
    "\n",
    "plt.figure(figsize=(12, 12))  # Set the figure size\n",
    "for i, col in enumerate(numeric_columns, 1):\n",
    "    plt.subplot(int(len(numeric_columns)**0.5) + 1, int(len(numeric_columns)**0.5) + 1, i)\n",
    "    sns.boxplot(y=df[col], color=colors[i - 1])\n",
    "    plt.title(col, fontsize=10)\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873edd8f",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ“Š Here we see there is no outlier in the numerical columns because when we normalize the numerical columns, the outliers are automatically removed. âœ…ğŸ“ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89f87bd",
   "metadata": {},
   "source": [
    "\n",
    "</div> \n",
    "<div style=\"font-size: 24px; font-weight: 600; color: #ff4d4d; background: linear-gradient(90deg, #3c1b4d, #6b2d8a); padding: 18px; border-radius: 40px; text-align: center; width: 420px; height: 60px; line-height: 60px; margin: 10px auto; box-shadow: 0 4px 12px rgba(0,0,0,0.2); font-family: 'Helvetica Neue', Arial, sans-serif; letter-spacing: 0.5px; position: relative; overflow: hidden;\">\n",
    "    <span style=\"position: relative; z-index: 1;\">ğŸ§  Step 8: Deep Learning ğŸ“–</span>\n",
    "    <div style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; background: radial-gradient(circle, rgba(255,255,255,0.1), transparent); opacity: 0.5; z-index: 0;\"></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8b5ee1",
   "metadata": {},
   "source": [
    "## Let's start the Deep Learning ğŸ§ âœ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b276e9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reproducibility settings\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Example: import pandas as pd; df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Ensure column names are stripped of extra spaces\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Check available columns\n",
    "print(\"Available columns in DataFrame:\", df.columns.tolist())\n",
    "\n",
    "# Check if 'Budget(INR)' exists\n",
    "if 'Budget(INR)' not in df.columns:\n",
    "    raise KeyError(\"'Budget(INR)' column is missing. Available columns: \" + str(df.columns.tolist()))\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(['Budget(INR)'], axis=1)\n",
    "y = df['Budget(INR)']\n",
    "\n",
    "# Encode categorical columns\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# Apply log1p transformation to numerical columns\n",
    "numerical_cols = ['Number of Screens', 'Revenue(INR)']\n",
    "numerical_cols = [col for col in numerical_cols if col in X.columns]\n",
    "if numerical_cols:\n",
    "    X[numerical_cols] = X[numerical_cols].apply(np.log1p)\n",
    "else:\n",
    "    print(\"Warning: No numerical columns found for log1p transformation.\")\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define model-building function for KerasTuner\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units_1', min_value=64, max_value=192, step=32),  # Reduced range\n",
    "        input_dim=X_train.shape[1],\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.1, max_value=0.3, step=0.1)))\n",
    "\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units_2', min_value=32, max_value=96, step=16),  # Reduced range\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(hp.Float('dropout_2', min_value=0.1, max_value=0.2, step=0.1)))\n",
    "\n",
    "    model.add(Dense(1))  # Output layer\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=5e-3, sampling='log')\n",
    "        ),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Set up KerasTuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=50,  # Reduced for speed\n",
    "    factor=3,\n",
    "    directory='tuner_dir',\n",
    "    project_name='budget_prediction',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)  # Reduced patience\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "# Search for best hyperparameters\n",
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=100,  # Reduced from 200\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters()[0]  # Fixed error\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(f\"Units (Layer 1): {best_hps.get('units_1')}\")\n",
    "print(f\"Units (Layer 2): {best_hps.get('units_2')}\")\n",
    "print(f\"Dropout (Layer 1): {best_hps.get('dropout_1')}\")\n",
    "print(f\"Dropout (Layer 2): {best_hps.get('dropout_2')}\")\n",
    "print(f\"Learning Rate: {best_hps.get('learning_rate')}\")\n",
    "\n",
    "# Build the best model\n",
    "best_model = Sequential()\n",
    "best_model.add(Dense(\n",
    "    units=best_hps.get('units_1'),\n",
    "    input_dim=X_train.shape[1],\n",
    "    activation='relu'\n",
    "))\n",
    "best_model.add(BatchNormalization())\n",
    "best_model.add(Dropout(best_hps.get('dropout_1')))\n",
    "\n",
    "best_model.add(Dense(\n",
    "    units=best_hps.get('units_2'),\n",
    "    activation='relu'\n",
    "))\n",
    "best_model.add(BatchNormalization())\n",
    "best_model.add(Dropout(best_hps.get('dropout_2')))\n",
    "\n",
    "best_model.add(Dense(1))\n",
    "\n",
    "# Compile the best model\n",
    "best_model.compile(\n",
    "    optimizer=Adam(learning_rate=best_hps.get('learning_rate')),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# Train the best model\n",
    "print(\"\\nTraining best model...\")\n",
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=200,  # Reduced from 300\n",
    "    batch_size=64,  # Fixed for speed\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predict\n",
    "predictions = best_model.predict(X_test).flatten()\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(f\"\\n MAE: {mae}\")\n",
    "print(f\" MSE: {mse}\")\n",
    "print(f\" RÂ² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17071b2",
   "metadata": {},
   "source": [
    "- âœ¨ Here we get the Best result using Deep Learning. ğŸ§ ğŸ“Š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc35c67",
   "metadata": {},
   "source": [
    "\n",
    "</div> \n",
    "<div style=\"font-size: 24px; font-weight: 600; color: #ff4d4d; background: linear-gradient(90deg, #3c1b4d, #6b2d8a); padding: 18px; border-radius: 40px; text-align: center; width: 420px; height: 60px; line-height: 60px; margin: 10px auto; box-shadow: 0 4px 12px rgba(0,0,0,0.2); font-family: 'Helvetica Neue', Arial, sans-serif; letter-spacing: 0.5px; position: relative; overflow: hidden;\">\n",
    "    <span style=\"position: relative; z-index: 1;\">ğŸ’» Step 9: Save the Model ğŸ“–</span>\n",
    "    <div style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; background: radial-gradient(circle, rgba(255,255,255,0.1), transparent); opacity: 0.5; z-index: 0;\"></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7574406a",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Save Model ğŸ“¦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29ebebb",
   "metadata": {},
   "source": [
    "- âœ¨ We see the model using pickle ğŸ“¦ğŸ”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfad678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save model architecture, weights, scaler, and label encoders\n",
    "label_encoders = {col: LabelEncoder().fit(X[col]) for col in X.columns if X[col].dtype == 'object'}\n",
    "model_data = {\n",
    "    'model_json': best_model.to_json(),\n",
    "    'model_weights': best_model.get_weights(),\n",
    "    'scaler': scaler,\n",
    "    'label_encoders': label_encoders\n",
    "}\n",
    "\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "print(\"Model saved to 'model.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae8ceef",
   "metadata": {},
   "source": [
    "\n",
    "</div> \n",
    "<div style=\"font-size: 24px; font-weight: 600; color: #ff4d4d; background: linear-gradient(90deg, #3c1b4d, #6b2d8a); padding: 18px; border-radius: 40px; text-align: center; width: 420px; height: 60px; line-height: 60px; margin: 10px auto; box-shadow: 0 4px 12px rgba(0,0,0,0.2); font-family: 'Helvetica Neue', Arial, sans-serif; letter-spacing: 0.5px; position: relative; overflow: hidden;\">\n",
    "    <span style=\"position: relative; z-index: 1;\">ğŸ“¦ Step 10: Load the Model ğŸ“–</span>\n",
    "    <div style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; background: radial-gradient(circle, rgba(255,255,255,0.1), transparent); opacity: 0.5; z-index: 0;\"></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f63bba",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Load the Model ğŸ“¦âœ¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267ac8c0",
   "metadata": {},
   "source": [
    "- âœ¨ğŸ“¦ Let's load the model ğŸ”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# Load model data\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model_data = pickle.load(f)\n",
    "\n",
    "# Rebuild model\n",
    "loaded_model = model_from_json(model_data['model_json'])\n",
    "loaded_model.set_weights(model_data['model_weights'])\n",
    "loaded_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Extract scaler and label encoders\n",
    "scaler = model_data['scaler']\n",
    "label_encoders = model_data['label_encoders']\n",
    "\n",
    "print(\"Model, scaler, and label encoders loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3acd7fb",
   "metadata": {},
   "source": [
    "ğŸ”” **If you found this notebook helpful, please don't forget to give it an upvote!** â¤ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2055c4d",
   "metadata": {},
   "source": [
    "\n",
    "Note: Some parts of this notebook were developed with the assistance of AI tools. The content has been reviewed, customized, and verified to ensure accuracy and originality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
